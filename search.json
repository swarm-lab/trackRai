[{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://swarm-lab.github.io/trackRai/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://swarm-lab.github.io/trackRai/articles/z1_install.html","id":"package-installation","dir":"Articles","previous_headings":"","what":"1. Package installation","title":"1. Installing trackRai","text":"trackRai currently available CRAN. can install trackRai rest dependencies simply typing following command R console:","code":"pak::pak(\"swarm-lab/trackRai\")"},{"path":"https://swarm-lab.github.io/trackRai/articles/z1_install.html","id":"from-cran","dir":"Articles","previous_headings":"","what":"1.1. From CRAN","title":"1. Installing trackRai","text":"trackRai currently available CRAN.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z1_install.html","id":"from-github","dir":"Articles","previous_headings":"","what":"1.2. From GitHub","title":"1. Installing trackRai","text":"can install trackRai rest dependencies simply typing following command R console:","code":"pak::pak(\"swarm-lab/trackRai\")"},{"path":"https://swarm-lab.github.io/trackRai/articles/z1_install.html","id":"setting-up-trackrai","dir":"Articles","previous_headings":"","what":"2. Setting up trackRai","title":"1. Installing trackRai","text":"recommended run trackRai machine equipped NVIDIA graphics card CUDA toolkit. computer equipped NVIDIA graphics card, can find instructions install CUDA : Windows computers: https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/ Linux computers: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/ computer equipped NVIDIA graphics card CUDA toolkit installed , can still use trackRai training YOLO model may take long time (several hours). Note: time writing, YOLO (therefore, trackRai) compatible CUDA versions 11.8, 12.4, 12.6. trackRai installed, need install YOLO machine using helper function install_yolo() provided trackRai. installer prompt series questions. Answer “Yes” every time want YOLO dependencies installed machine. Answering “” may stop installation process trackRai may usable. may also need restart R session able use apps provided trackRai. Note: default, install_yolo() attempt install Python 3.12.5 system already present. errors happen installation Python, prefer installing another version, can using “python_version” parameter install_yolo(). YOLO currently compatible Python 3.8.0 3.12.8, versions work. Note: Windows computer, install_yolo() attempt automatically detect version CUDA installed machine. can override using “cuda_win_version” parameter.","code":"library(trackRai) install_yolo()"},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_1_prepare_video.html","id":"introduction","dir":"Articles","previous_headings":"","what":"0. Introduction","title":"2.1. Optimizing a video for YOLO","text":"ready preprocess video, can launch trackRai typing following command R console:  open app launcher either viewer pane RStudio Positron, separate window, depending local configuration. RStudio least, can control app opens setting launch.browser option. instance: launch app RStudio viewer pane. launcher running, click “Prepare” button, “Video optimization” one launch video preparation app. launcher close app start shortly . app help prepare video way optimal YOLO training. particular, able trim video remove unnecessary parts, select region interest focus analysis , reduce resolution video needed. app also ensure dimensions video multiples 32, help speed image processing performed YOLO.","code":"library(trackRai) trackRai() trackRai(launch.browser = shiny::paneViewer())"},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_1_prepare_video.html","id":"video-module","dir":"Articles","previous_headings":"","what":"1. Video module","title":"2.1. Optimizing a video for YOLO","text":"first step process load video file app. , simply click “Select video” button. bring navigator use locate video file like process. located video file navigator, click “Select” button. app open video display first image display window (see ).  can navigate video sliding green tab along timeline displayed video. gray tabs can used restrict analysis specific time interval video. can also use arrow keys keyboard navigate video: left right arrows allow navigate frame frame; arrows allow navigate one second time. “Rescaling factor” drop-menu allows scale resolution video needed. objects want track large, help reduce computational load training tracking processes. objects want track small, however, probably want keep resolution high possible. “Rescaling factor” drop-menu, find four buttons allow set top, bottom, left, right boundaries region interest video. Click button corresponding boundary want set, click video set .  done, click “Export video” button save optimized video. bring file manager can select location like video saved. export process terminates, done can close app. video used throughout tutorial provided Sridhar, V. H., Roche, D. G., Gingins, S. (2019). Tracktor: Image-based automated tracking animal movement behaviour. Methods Ecol. Evol. 10, 691. doi:10.1111/2041-210X.13166 used permission authors.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_auto.html","id":"introduction","dir":"Articles","previous_headings":"","what":"0. Introduction","title":"2.2. Preparing a training dataset (automatic annotation)","text":"ready prepare training dataset, can launch trackRai typing following command R console:  open app launcher either viewer pane RStudio Positron, separate window, depending local configuration. RStudio least, can control app opens setting launch.browser option. instance: launch app RStudio viewer pane. launcher running, click “Prepare” button, “Auto annotation” one launch data preparation app. launcher close app start shortly . app help generate dataset can use train YOLO model. idea use traditional computer vision techniques isolate single instances objects like track, well background objects moving. use create composite images random arrangements arbitrary large number isolated objects. Using approach, can generate automatically large number training images YOLO, without requiring manual labelling. Note: approach works well background video stable, , ideally, camera movement lighting variations. Good tracking results guaranteed otherwise. complicated scenarios, use instead “Manual annotation” option described .","code":"library(trackRai) trackRai() trackRai(launch.browser = shiny::paneViewer())"},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_auto.html","id":"video-module","dir":"Articles","previous_headings":"","what":"1. Video module","title":"2.2. Preparing a training dataset (automatic annotation)","text":"first step preparation process load video file app. , simply click “Select video” button. bring navigator use locate video file like process. located video file navigator, click “Select” button. app open video display first image display window (see ).  can navigate video sliding green tab along timeline displayed video. gray tabs can used restrict analysis specific time interval video. can also use arrow keys keyboard navigate video: left right arrows allow navigate frame frame; arrows allow navigate one second time. app opened video, can move “Background module” clicking tab marked “2” right side control panel.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_auto.html","id":"background-module","dir":"Articles","previous_headings":"","what":"2. Background module","title":"2.2. Preparing a training dataset (automatic annotation)","text":"“Background module”, can either choose load existing background image (e.g., image empty experimental setup start experiment) can ask app automatically reconstruct background video.  choose select existing background image, just click “Select existing background” button use navigator locate select desired image. can skip rest section go directly next section. choose let app reconstruct background video, first need decide two things: “Mean” computes background image pixel average corresponding pixels selected video frames. fast algorithm. However always produce good results. “Median” computes background image pixel median corresponding pixels selected video frames. usually produces better result “Mean”, take longer complete. “Minimum” computes background image pixel minimum corresponding pixels selected video frames. usually produces good result objects isolate lighter background. “Maximum” computes background image pixel maximum corresponding pixels selected video frames. usually produces good result objects isolate darker background. “Number frames estimating background”. Better results usually obtained larger number frames background slower reconstruct. selected two parameters, click “Automatically estimate background” button app start reconstructing background video. occasions, like image left , app reconstruct background completely. can happen, instance, object move entirety video like case .  can fix “ghosts” clicking “Select ghost removal” button. allow draw polygon around object remove background using left button mouse/trackpad. surrounded object polygon, use return key keyboard close polygon. app use pixels surrounding polygon traced replace object best guess color background . Note: ghost removal mode basic may yield good results complex backgrounds. Another option save background file ghosts use advanced image editing software remove (instance, Photoshop’s Remove tool can give much better results). happy background generated app, can click “Save background file” button save background image later (re)use.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_auto.html","id":"mask-module","dir":"Articles","previous_headings":"","what":"3. Mask module","title":"2.2. Preparing a training dataset (automatic annotation)","text":"“Mask module” optional can skipped. used like restrict extraction instances specific areas image, instance exclude outside experimental arena things may moving tracked (e.g., hands experimenter). default, app use entirety visible frame perform tracking.  control panel “Mask module” allows either use existing mask design . use existing mask, click “Select existing mask” button use navigator locate select desired mask image. mask image grayscale image resolution video. Non-black portions image included tracking black portion excluded. Different shades gray can used delimit different parts mask. like design mask (modify existing mask loaded app), can use following controls: “Include ” tells app use entirety visible frame perform tracking. useful button reset mask default setting. “Exclude ” tells app use none visible frame perform tracking. useful button wipe mask adding authorized areas tracking using “Add polygon ROI” ”Add ellipse ROI” buttons. “Add polygon ROI” (region interest) allows draw polygon mask using left button mouse/trackpad. sastified polygon, use return key keyboard close . “Including” radio button selected, area inside polygon included tracking. Otherwise, excluded. “Add ellipse ROI” allows draw ellipse mask indicating 5 points along periphery area interest. Use left button mouse/trackpad . finished adding 5 points, app compute ellipse best fitting . recommended select 5 points roughly equidistant along periphery area interest. “Including” radio button selected, area inside ellipse included tracking. Otherwise, excluded. “ROI id” allows assign unique identifier region interest, allowing separating tracking objects post-processing.  can combine including/excluding polygons ellipses define mask complex detailed like. Included areas take slightly greener tint display window excluded areas take slightly red tint (see images ). satisfied design, can save later (re)use clicking “Save mask file” button.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_auto.html","id":"segmentation-module","dir":"Articles","previous_headings":"","what":"4. Segmentation module","title":"2.2. Preparing a training dataset (automatic annotation)","text":"Segmentation process isolating objects interests background image. order , app first needs know whether looking objects darker lighter background. can ticking appropriate radio button top control panel “Segmentation module”.  done, app need know different background pixel must considered part one objects isolate. order indicate information app, can use threshold slider control panel. allow set threshold difference pixel considered part object part background. objective find threshold creates good separation objects isolate background. can see result changing thresholds display window: parts image considered object given threshold surrounded green line (see image ). good threshold result green lines tightly following edges objects isolate. can also let app search good threshold clicking “Autothreshold” button control panel. app can use multiple methods estimate threshold provides good segmentation results. can try select method using drop-menu next “Autothreshold” button, observe effect running autothresholding operation . can tweak manually suggested threshold want. Finally, can exclude fine details objects isolate (e.g., legs termites image ) playing “Contour smoothing“ slider. can useful obtain accurate tracking centers mass objects (fine details can introduce unnecessary noise trajectory). recommended look result segmentation process different parts video using control slider video display. ensure selected threshold gives good results throughout video.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_auto.html","id":"identification-module","dir":"Articles","previous_headings":"","what":"5. Identification module","title":"2.2. Preparing a training dataset (automatic annotation)","text":"purpose module identify segmented parts image represent single instances objects want track. segmented portion image displayed surrounded rectangle. can increase decrease size rectangles using “Shape buffer” slider control panel app. Ideally, want rectangle encloses completely whole body instance objects track. two instances close , may enclosed rectangle, fine, long enough instances singled .  shape buffer set, click “Detect instances” button. measure width height rectangle across set number frames (can adjust numerical input field next button). “Automatic instance selection” tick box checked, app suggest range widths heights corresponding rectangles likely represent single instances. can untick box manually adjust ranges. results selection process displayed graph control panel colors rectangles display window. Green dots (rectangles) represent objects thought single instances. Red-orange dots represent objects thought single instances (.e., either multiple instances incomplete instances). can navigate selected frames review results instance selection. one objects correctly identified, can click change status (green red-orange, vice versa). Note: modify buffer size number images used detect instances computing statistics, need run instance detection take account new parameters.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_auto.html","id":"composite-module","dir":"Articles","previous_headings":"","what":"6. Composite module","title":"2.2. Preparing a training dataset (automatic annotation)","text":"final step process generate training dataset . create composite images set number instances printed background image, random locations orientations within boundary mask loaded/created earlier. also create bounding boxes objects YOLO needs learn objects look like.  First, set “Number instances” included composite images. number instances high enough result lot random arrangements overlaps YOLO can generalize better situations objects touch overlap. can also set “Mask buffer” zone ensure printed objects overlap much mask boundaries (.e., stick observation area). Similarly, can set “Overlap buffer” reduce amount overlap instances, instance, know objects overlap much real life. Next, can “Add random image noise” composite images order increase generalizability YOLO training. can also “Add random gain” “Add random bias” randomly change contrast luminosity composite images even generalizability. check effect parameter resulting composite images, can click “Generate test composite” button generate one sample composite images. satisfied results, can set number images used training, validating, testing YOLO model train separate app. recommended breakdown reserve 70% images training, 15% validating testing, respectively. can generate training dataset clicking “Generate YOLO dataset” button. bring file manager can select location like dataset saved (folder named “YOLO” created location). process terminates, done can close app. next step training YOLO model using dataset just created. video used throughout tutorial provided Sridhar, V. H., Roche, D. G., Gingins, S. (2019). Tracktor: Image-based automated tracking animal movement behaviour. Methods Ecol. Evol. 10, 691. doi:10.1111/2041-210X.13166 used permission authors.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_manual.html","id":"introduction","dir":"Articles","previous_headings":"","what":"0. Introduction","title":"2.3. Preparing a training dataset (manual annotation)","text":"ready prepare training dataset, can launch trackRai typing following command R console:  open app launcher either viewer pane RStudio Positron, separate window, depending local configuration. RStudio least, can control app opens setting launch.browser option. instance: launch app RStudio viewer pane. launcher running, click “Prepare” button, “Manual annotation” one launch data preparation app. launcher close app start shortly . app help generate dataset can use train YOLO model. app provides interface quickly annotate video frames hand, instead using automated method discussed . less convenient, advantage working complicated scenarios, instance want track different classes objects separately, scene complex /variable (e.g., camera movement, changing background, unstable light conditions, etc).","code":"library(trackRai) trackRai() trackRai(launch.browser = shiny::paneViewer())"},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_manual.html","id":"video-module","dir":"Articles","previous_headings":"","what":"1. Video module","title":"2.3. Preparing a training dataset (manual annotation)","text":"first step preparation process load video file app. , simply click “Select video” button. bring navigator use locate video file like process. located video file navigator, click “Select” button. app open video display first image display window (see ).  can navigate video sliding green tab along timeline displayed video. can also use arrow keys keyboard navigate video: left right arrows allow navigate frame frame; arrows allow navigate one second time. app opened video, can move “Segmentation module” clicking tab marked “2” right side control panel.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_manual.html","id":"segmentation-module","dir":"Articles","previous_headings":"","what":"2. Segmentation module","title":"2.3. Preparing a training dataset (manual annotation)","text":"Segmentation process isolating objects interests background image. order , app need help . First, ’ll need create tags class object want track. drop-menu “Object tags (type add new tag)”, can add new class objects simply typing name like use class. can add many classes want, need specify least one class proceed. specified several classes, can cycle using [e] key keyboard.  created object tags, can start annotating frames video. frames used later train YOLO model recognize objects classes video (similar videos). Ideally, want annotate many frames possible, good results can achieved annotating 50 frames. important: objects interest frame must annotated! annotate objects, YOLO might learn ignore , opposite trying achieve. annotate object frame, click “Add object [q]” button, press [q] key keyboard. bring cross-hair cursor can use select two points extreme ends long axis object (e.g., just front head just behind tail animal). app use information create oriented bounding box around object. satisfied result, can click “Remove object [w]” button, press [w] key keyboard. Click inside bounding box object want remove.  objects annotated, can navigate another using navigation controls described previous section. Ideally, want annotate frames represent variety situations, recommended spread frames select. can also click “Select random frame [r]” button, press [r] key keyboard. pick frame random video ensuring spread across video (.e., portions video covered well likely selected time). facilitate annotation process crowded condition, possible show/hide bounding boxes tags using tick boxes called “Show boxes” “Show tags”. annotated frames can accessed “Tagged frames” drop-menu. allow quickly navigate frame contains annotated objects, example, review someone else’s work. Statistics number annotated frames, tagged objects, tagged objects current frame can found . Finally, importantly, can save work progress clicking “Save state” button bottom control panel. save current state app, can load back later time clicking “Load state” button. especially useful complete annotation one session, want return work later add annotations (e.g., result training process satisfying).","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z2_prepare_manual.html","id":"yolo-module","dir":"Articles","previous_headings":"","what":"3. YOLO module","title":"2.3. Preparing a training dataset (manual annotation)","text":"final step process generate training dataset . First, need set number images used training, validating, testing YOLO model train separate app. recommended breakdown–strict rule–reserve 70% images training, 15% validating testing, respectively.  can also decide enrich training dataset adding copies annotated frames random noise, luminosity, contrast changes applied. increase diversity training dataset can improve generalizability model. means mandatory step, can play see improves results. ready, can generate training dataset clicking “Generate YOLO dataset” button. bring file manager can select location like dataset saved (folder named “YOLO” created location). process terminates, done can close app. next step training YOLO model using dataset just created. video used throughout tutorial provided Gal, ., Saragosti, J., & Kronauer, D. J. (2020). anTraX, software package high-throughput video tracking color-tagged insects. eLife, 9. https://doi.org/10.7554/eLife.58145, used terms Creative Commons Attribution 4.0 International License.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z3_train.html","id":"introduction","dir":"Articles","previous_headings":"","what":"0. Introduction","title":"3. Training a YOLO model","text":"ready train YOLO model, can launch trackRai typing following command R console:  open app launcher either viewer pane RStudio Positron, separate window, depending local configuration. RStudio least, can control app opens setting launch.browser option. instance: launch app RStudio viewer pane. launcher running, click “Train” button launch YOLO training app. launcher close app start shortly . app help train YOLO11 model using dataset created previous tutorial. process straightforward, however, might take time depending configuration system. machine NVIDIA graphics card CUDA framework installed highly recommended.","code":"library(trackRai) trackRai() trackRai(launch.browser = shiny::paneViewer())"},{"path":"https://swarm-lab.github.io/trackRai/articles/z3_train.html","id":"training-module","dir":"Articles","previous_headings":"","what":"1. Training module","title":"3. Training a YOLO model","text":"app opens, presented “Training” tab. Click “Select training dataset” button navigate folder containing YOLO dataset prepared one previous tutorials (folder named “YOLO”). Select folder. , select model size. Smaller models take less time memory train, larger models may yield better results complex arrangements objects. find smaller (“nano”) model size really good job situations. Finally, can “Set number training epochs” like run “patience” training process. last parameter allows training stop automatically training performance improve set number epochs. helps prevent overfitting stopping training performance plateaus; also saves computing time. want training stop early, set patience maximum number epochs.  setting training parameters, click “Start training” button wait completes. Performance metrics displayed graph left window, log panel graph. training completed successfully, second tab app become available can click navigate .","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z3_train.html","id":"checking-module","dir":"Articles","previous_headings":"","what":"2. Checking module","title":"3. Training a YOLO model","text":"second tab training app, can check quality training effect inference parameters detection objects interest video. First, need select video clicking “Select video” button. can also select optional mask clicking “Select mask (optional)” button. load video app navigate sliding green tab along timeline displayed video. can also use arrow keys keyboard navigate video: left right arrows allow navigate frame frame; arrows allow navigate one second time. Detected objects automatically enclosed colored rectangle class overlaid top (can show/hide boxes class tags using corresponding tick boxes bottom control panel).  can check effect following parameters quality object detection: Minimum confidence threshold: minimum confidence threshold detection. Objects detected confidence threshold disregarded. Adjusting value can help reduce false positives. Intersection union threshold: threshold non-maximum suppression. Lower values result fewer detection eliminating overlapping boxes, can useful reducing duplicates. Maximum number objects detect: Maximum number detection allowed per frame. Limits total number objects model can detect single inference, preventing excessive outputs dense scenes. satisfied detection results, can return first tab increase number training epochs /patience training, select larger model size, running another round training. satisfied results, done can close app. next step using trained model track objects video. video used throughout tutorial provided Sridhar, V. H., Roche, D. G., Gingins, S. (2019). Tracktor: Image-based automated tracking animal movement behaviour. Methods Ecol. Evol. 10, 691. doi:10.1111/2041-210X.13166 used permission authors.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z4_track.html","id":"introduction","dir":"Articles","previous_headings":"","what":"0. Introduction","title":"4. Tracking objects","text":"ready track objects video, can launch trackRai typing following command R console:  open app launcher either viewer pane RStudio Positron, separate window, depending local configuration. RStudio least, can control app opens setting launch.browser option. instance: launch app RStudio viewer pane. launcher running, click “Track” button launch tracking app. launcher close app start shortly . app help track objects video using trained YOLO11 model, explained previous tutorial. recommended train model machine NVIDIA graphics card CUDA framework installed, tracking can done reasonable performance machines without specifications.","code":"library(trackRai) trackRai() trackRai(launch.browser = shiny::paneViewer())"},{"path":"https://swarm-lab.github.io/trackRai/articles/z4_track.html","id":"data-module","dir":"Articles","previous_headings":"","what":"1. Data module","title":"4. Tracking objects","text":"app opens, presented “Data” module. First, need select video clicking “Select video” button. can also select optional mask clicking “Select mask (optional)” button. load video app. can navigate video sliding green tab along timeline displayed video. gray tabs can used restrict analysis specific time interval video. can also use arrow keys keyboard navigate video: left right arrows allow navigate frame frame; arrows allow navigate one second time.  Finally, need select trained YOLO dataset clicking “Select trained dataset” button navigate folder containing trained YOLO dataset (folder named ”YOLO”). Select folder. folder contains multiple trained models, can select one choice using drop-menu bottom sidebar. video trained dataset loaded app, second tab app become available can click navigate .","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z4_track.html","id":"scaling-module","dir":"Articles","previous_headings":"","what":"2. Scaling module","title":"4. Tracking objects","text":"default, app set origin coordinate system top-left corner video. can change clicking “Set origin” button control panel. use mouse click location video frame want origin .  can also set scaling factor directly converting pixel coordinates real-world coordinates. , click “Set scale” button control panel. use mouse select two points video frame known certain distance apart real world. pop-window ask enter distance two points unit measurement want use. app automatically convert tracking results real-world coordinates .","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z4_track.html","id":"tracking-module","dir":"Articles","previous_headings":"","what":"3. Tracking module","title":"4. Tracking objects","text":"Finally, tracking module magic happens. , need set parameters. detection parameters used YOLO decide parts image contains object interest. parameters : “Maximum number objects detect”: maximum number detected objects allowed per frame. limits total number objects model can detect single inference, preventing excessive outputs dense scenes. “Minimum confidence threshold”: minimum confidence threshold detecting object. Objects detected confidence threshold disregarded. Adjusting value can help reduce false positives. “Intersection union threshold”: threshold non-maximum suppression. Lower values result fewer detected objects eliminating overlapping boxes, can useful reducing duplicates. effect parameters detection quality can seen directly display panel.  tracking parameters used YOLO decide object given frame corresponds object following frame. parameters : “Association thresholds”: highest value threshold used initial association detected object track. detection’s score threshold, object associated track first round association process. lowest value threshold used secondary association. detected object wasn’t associated first round score higher , might still associated track second round association process. “New track threshold”: threshold used starting new track. detected object doesn’t match existing tracks score threshold, new track initialized. “Old track buffer”: number frames allowed pass without receiving updates track removed. Higher values allow tracks remain active longer without updates, might help object detected every single frame, also increase risk tracking errors. “Track matching threshold”: threshold used matching tracks consecutive frames. tracks score threshold considered matching. directly observe effect parameters display panel. However, can run tracking small portion video use “Show preview” mode evaluate quality resulting tracks. satisfied selected parameters, can start tracking clicking “Start tracking” button. open file browser can select save results tracking. like see preview tracks tracking running, tick “Show preview” tick box.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z4_track.html","id":"output","dir":"Articles","previous_headings":"","what":"4. Output data","title":"4. Tracking objects","text":"app done processing video, resulting CSV file contain 8 12 columns depending whether set real-world scale origin “Scale module”. columns following: “frame” video frame number measurements along corresponding row made. “track” identity tracked object estimated app. “class” class tracked object. “x” x coordinate object location pixels context video frame. origin set top-left corner frame. “y” y coordinate object location pixels context video frame. origin set top-left corner frame. “width” width pixels object. “height” height pixels object. “angle” angle degrees main axis object y axis. set real-world scale origin “Scaling module”, following extra columns saved: “x_[unit]” x coordinate object location real-world [unit]. origin set real-world equivalent defined “Scale module”. “y_[unit]” y coordinate object location real-world [unit]. origin set real-world equivalent defined “Tracking module”. “width_[unit]” width real-world [unit] object. “height_[unit]” height real-world [unit] object. video used throughout tutorial provided Sridhar, V. H., Roche, D. G., Gingins, S. (2019). Tracktor: Image-based automated tracking animal movement behaviour. Methods Ecol. Evol. 10, 691. doi:10.1111/2041-210X.13166 used permission authors.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z5_fix.html","id":"introduction","dir":"Articles","previous_headings":"","what":"0. Introduction","title":"5. Fixing tracks","text":"finished tracking video, can manually inspect results fix potential error using track fixing app provided package. can launch app typing following command R console:  open app launcher either viewer pane RStudio Positron, separate window, depending local configuration. RStudio least, can control app opens setting launch.browser option. instance: launch app RStudio viewer pane. launcher running, click “Fix” button launch tracking app. launcher close app start shortly .","code":"library(trackRai) trackRai() trackRai(launch.browser = shiny::paneViewer())"},{"path":"https://swarm-lab.github.io/trackRai/articles/z5_fix.html","id":"fixer-module","dir":"Articles","previous_headings":"","what":"1. Fixer module","title":"5. Fixing tracks","text":"first step fixing process load video file tracking data app. , simply click “Select video” button. bring navigator use locate video file like track. located video file navigator, click “Select” button. app open video display first image display window (see ). Repeat process “Select tracks” button load tracking data. done, tracked objects indicated colored box number corresponding tracked identity (see ).  can navigate video sliding green tab along timeline displayed video. can also use arrow keys keyboard navigate video: left right arrows allow navigate frame frame; arrows allow navigate one second time. navigation controls, find drop-menu lists series suspected issues tracking data. simply positions video existing track suddenly disappears, new track suddenly appears. necessarily indicate actual error, often indicative problem tracking. can navigate suspected issues selecting drop-menu. 6 buttons allow perform number correcting operations find trackR made mistake tracking: “Reassign” button (“q” key keyboard) open reassignment menu. menu opened, can use first drop-selector select track assign new number reassign previously existing track. can type input box number like assign track. “Remove” button (“w” key keyboard) open removal menu. menu opened, can use drop-selector select track remove. “Swap IDs” button (“e” key keyboard) open ID swapping menu. menu opened, can use two drop-selectors select tracks swap. Note swapping occur frame . Previous frames affected tracks retain original ID. “Merge IDs” button (“r” key keyboard) open ID merging menu. menu opened, can use two drop-selectors select tracks merge together. Note resulting track retain ID first selected track. “Undo” button (“” key keyboard) undo change made fixing session reverse order made. “Save” button (“s” key keyboard) save modifications made fixing session. modifications saved different file one containing original tracking results prevent accidental modifications permanently damage original results. modified file name saved location original file “_fixed” appended name. Note interrupt fixing session end video, can resume loading “[original_file_name]_fixed.csv” file instead original one. case, new correction also saved “[original_file_name]_fixed.csv” file. buttons, basic statistics tracks displayed fixing controls. can useful track progress fixing session. instance, statistics table shows file contains 10 tracks know 8 individuals experiment, good indication errors remain fixed. Finally, bottom control panel, can modify “Tag scale” “Tag line width” parameters make track tags visible video. can also toggle “Show IDs” “Show boxes” buttons show/hide tags boxes overlaid top image. can useful trying tell apart objects close .","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z5_fix.html","id":"output-data","dir":"Articles","previous_headings":"","what":"2. Output data","title":"5. Fixing tracks","text":"click “Save” button app, data saved “[original_file_name]_fixed.csv” file columns saved originally tracking app (see details). file also contain 2 additional columns: “track_fixed” identity tracked object corrections applied. track column retains original, uncorrected identity. “ignore” indicates whether can ignore (TRUE) (FALSE) corresponding row analyze data. Ignored rows , instance, tracks chosen remove merge another track. video used throughout tutorial provided Sridhar, V. H., Roche, D. G., Gingins, S. (2019). Tracktor: Image-based automated tracking animal movement behaviour. Methods Ecol. Evol. 10, 691. doi:10.1111/2041-210X.13166 used permission authors.","code":""},{"path":"https://swarm-lab.github.io/trackRai/articles/z6_visualize.html","id":"introduction","dir":"Articles","previous_headings":"","what":"0. Introduction","title":"6. Visualizing tracks","text":"tracking dataset ready, can visualize using trajectory visualization app provided package. can launch app typing following command R console:  open app launcher either viewer pane RStudio Positron, separate window, depending local configuration. RStudio least, can control app opens setting launch.browser option. instance: launch app RStudio viewer pane. launcher running, click “Visualize” button launch visualization app. launcher close app start shortly .","code":"library(trackRai) trackRai() trackRai(launch.browser = shiny::paneViewer())"},{"path":"https://swarm-lab.github.io/trackRai/articles/z6_visualize.html","id":"player-module","dir":"Articles","previous_headings":"","what":"1. Player module","title":"6. Visualizing tracks","text":"first step visualization process load video file tracking data app. , simply click “Select video” button. bring navigator use locate video file like track. located video file navigator, click “Select” button. app` open video display first image display window (see ). Repeat process “Select tracks” button load tracking data. done, tracked objects indicated colored box number corresponding tracked identity (see ).  can navigate video sliding green tab along timeline displayed video. can also use arrow keys keyboard navigate video: left right arrows allow navigate frame frame; arrows allow navigate one second time. navigation controls, find four numeric input fields: “Track width (pixels)” allows adjust width lines delineating tracked objects representing trajectories; “Track length (frames)” allows adjust number frames used represent trajectories tracked objects; “Tag scale” allows adjust font size tags represent identities tracked objects; “Tag line width” allows adjust font thickness tags. input fields, find four tick boxes allow show/hide ID number class object, colored boxes delineating , trajectories tracked objects taken fixed number frames. Finally, bottom app window, “Export video” button allows export video tracked objects superimposed . clicking button, app prompt select location save exported video. done, export start video saved selected location. video used throughout tutorial provided Sridhar, V. H., Roche, D. G., Gingins, S. (2019). Tracktor: Image-based automated tracking animal movement behaviour. Methods Ecol. Evol. 10, 691. doi:10.1111/2041-210X.13166 used permission authors.","code":""},{"path":"https://swarm-lab.github.io/trackRai/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Simon Garnier. Author, maintainer. National Science Foundation, Award ID 2222418. Funder.","code":""},{"path":"https://swarm-lab.github.io/trackRai/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Garnier S (2025). trackRai: Multi-Object Tracking YOLO11. R package version 0.1.0, https://github.com/swarm-lab/trackRai.","code":"@Manual{,   title = {trackRai: Multi-Object Tracking With YOLO11},   author = {Simon Garnier},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/swarm-lab/trackRai}, }"},{"path":[]},{"path":"https://swarm-lab.github.io/trackRai/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"Multi-Object Tracking With YOLO11","text":"trackRai YOLO-based multi-object tracking software R. provides easy--use (think) Shiny apps automating preparation training YOLO11 models, performing tracking multiple objects video range conditions maintaining individual identities. Finally, trackRai can leverage trackRcv’s convenience apps manually correct common errors occurs tracking, export publication-ready videos showing moving objects track overlaid top .","code":""},{"path":"https://swarm-lab.github.io/trackRai/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Multi-Object Tracking With YOLO11","text":"can install development version trackRai GitHub :","code":"# install.packages(\"pak\") pak::pak(\"swarm-lab/trackRai\")"},{"path":"https://swarm-lab.github.io/trackRai/index.html","id":"user-guides","dir":"","previous_headings":"","what":"User guides","title":"Multi-Object Tracking With YOLO11","text":"1. Installing trackRai 2. Preparing training dataset 3. Training YOLO model 4. Tracking objects 5. Fixing tracks 6. Visualizing tracks","code":""},{"path":"https://swarm-lab.github.io/trackRai/index.html","id":"faq","dir":"","previous_headings":"","what":"FAQ","title":"Multi-Object Tracking With YOLO11","text":"something break? Can use trackRai ‘production’ mode? Something definitely break. mostly one-person operation promise fully tested every single scenario challenge trackRai. said, work fine cases certainly usable tracking projects. run issue, please report : https://github.com/swarm-lab/trackRai/issues. – can help? trackRai open-source project, meaning can freely modify code implement new functionalities. coding skills, welcome contribute new code code improvement submitting pull requests GitHub repository project : https://github.com/swarm-lab/trackRai. best review integrate quickly. feel like contributing code, can also help submitting bug reports feature requests using issue tracker GitHub repository project : https://github.com/swarm-lab/trackRai/issues. extremely helpful catch correct errors code, guide development trackRai integrating functionalities requested community.","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/install_yolo.html","id":null,"dir":"Reference","previous_headings":"","what":"Install and Update YOLO — install_yolo","title":"Install and Update YOLO — install_yolo","text":"function automates installation/updating YOLO Python dependencies dedicated Python virtual environment use trackRai apps.","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/install_yolo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install and Update YOLO — install_yolo","text":"","code":"install_yolo(python_version = \"3.12.5\", cuda_win_version = \"auto\")"},{"path":"https://swarm-lab.github.io/trackRai/reference/install_yolo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install and Update YOLO — install_yolo","text":"python_version character string indicating version Python like YOLO run (default: \"3.12.5\"). YOLO currently compatible Python 3.8.0 3.12.8. versions Python necessarily work system, chosen default works systems tested far. cuda_win_version Windows-. character string indicating version CUDA installed computer. Valid values : auto (function tries determine automatically version CUDA, default), NA (YOLO installed without CUDA support), 11.8, 12.4, 12.6. values throw error. Ignored Mac Linux computers","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/install_yolo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Install and Update YOLO — install_yolo","text":"installation/update completes successfully, data frame indicating location YOLO installation version number.","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/install_yolo.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Install and Update YOLO — install_yolo","text":"requested version Python activated system, function attempt install first creating dedicated Python virtual environment.","code":""},{"path":[]},{"path":"https://swarm-lab.github.io/trackRai/reference/install_yolo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Install and Update YOLO — install_yolo","text":"Simon Garnier, garnier@njit.edu","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/remove_yolo.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove YOLO — remove_yolo","title":"Remove YOLO — remove_yolo","text":"function automates removal YOLO Python dependencies system.","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/remove_yolo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove YOLO — remove_yolo","text":"","code":"remove_yolo()"},{"path":"https://swarm-lab.github.io/trackRai/reference/remove_yolo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove YOLO — remove_yolo","text":"Nothing.","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/remove_yolo.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Remove YOLO — remove_yolo","text":"function remove dedicated Python virtual environment system. Python installed execution install_yolo(), removed.","code":""},{"path":[]},{"path":"https://swarm-lab.github.io/trackRai/reference/remove_yolo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Remove YOLO — remove_yolo","text":"Simon Garnier, garnier@njit.edu","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/trackRai-package.html","id":null,"dir":"Reference","previous_headings":"","what":"trackRai: Multi-Object Tracking With YOLO11 — trackRai-package","title":"trackRai: Multi-Object Tracking With YOLO11 — trackRai-package","text":"trackRai YOLO-based multi-object tracking software R. provides series Shiny apps automating preparation training YOLO11 models, performing tracking multiple objects video, visualizing results tracking process.","code":""},{"path":[]},{"path":"https://swarm-lab.github.io/trackRai/reference/trackRai-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"trackRai: Multi-Object Tracking With YOLO11 — trackRai-package","text":"Maintainer: Simon Garnier garnier@njit.edu (ORCID) contributors: National Science Foundation, Award ID 2222418 [funder]","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/trackRai.html","id":null,"dir":"Reference","previous_headings":"","what":"App Launcher — trackRai","title":"App Launcher — trackRai","text":"function starts app launcher gives user access Shiny apps provided trackRai.","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/trackRai.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"App Launcher — trackRai","text":"","code":"trackRai(...)"},{"path":"https://swarm-lab.github.io/trackRai/reference/trackRai.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"App Launcher — trackRai","text":"... Parameters passed shiny::runApp().","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/trackRai.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"App Launcher — trackRai","text":"function return anything.","code":""},{"path":[]},{"path":"https://swarm-lab.github.io/trackRai/reference/trackRai.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"App Launcher — trackRai","text":"Simon Garnier, garnier@njit.edu","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/trackRai.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"App Launcher — trackRai","text":"","code":"if (FALSE) { # \\dontrun{ trackRai() } # }"},{"path":"https://swarm-lab.github.io/trackRai/reference/yolo_installed.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect YOLO Installation — yolo_installed","title":"Detect YOLO Installation — yolo_installed","text":"function detects whether YOLO correctly installed system.","code":""},{"path":"https://swarm-lab.github.io/trackRai/reference/yolo_installed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect YOLO Installation — yolo_installed","text":"","code":"yolo_installed()"},{"path":"https://swarm-lab.github.io/trackRai/reference/yolo_installed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect YOLO Installation — yolo_installed","text":"logical indicating presence absence YOLO.","code":""},{"path":[]},{"path":"https://swarm-lab.github.io/trackRai/reference/yolo_installed.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Detect YOLO Installation — yolo_installed","text":"Simon Garnier, garnier@njit.edu","code":""}]
