<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>4 - Track objects in a video using a trained YOLO model • trackRai</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="4 - Track objects in a video using a trained YOLO model">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">trackRai</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/z1_installyolo.html">1 - Install YOLO11</a></li>
    <li><a class="dropdown-item" href="../articles/z2_prepare.html">2 - Prepare a dataset for training a YOLO model</a></li>
    <li><a class="dropdown-item" href="../articles/z3_train.html">3 - Train a YOLO model</a></li>
    <li><a class="dropdown-item" href="../articles/z4_track.html">4 - Track objects in a video using a trained YOLO model</a></li>
    <li><a class="dropdown-item" href="../articles/z5_visualize.html">5 - Visualize the results of tracking</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/swarm-lab/trackRai/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>4 - Track objects in a video using a trained YOLO model</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/swarm-lab/trackRai/blob/master/vignettes/z4_track.Rmd" class="external-link"><code>vignettes/z4_track.Rmd</code></a></small>
      <div class="d-none name"><code>z4_track.Rmd</code></div>
    </div>

    
    
<p>In this tutorial, we will discuss how to use the third app provided
with <code>trackRai</code> to track objects in a video using a trained
YOLO11 model, as explained in the <a href="https://swarm-lab.github.io/trackRai/articles/z3_train.html">previous
tutorial</a>. While it recommended to train the model on a machine with
an NVIDIA graphics card and the CUDA framework installed, tracking can
be done with reasonable performance on machines without these
specifications.</p>
<hr>
<div class="section level2">
<h2 id="launch-the-tracking-app">4.1 - Launch the tracking app<a class="anchor" aria-label="anchor" href="#launch-the-tracking-app"></a>
</h2>
<p>To launch the tracking app, run the following in the R console:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/swarm-lab/trackRai" class="external-link">trackRai</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/track.html">track</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>This will open the app either in the viewer panel of RStudio and
Positron, or in your default internet browser. You can control where the
app is opened using the <code>launch.browser</code> parameter (see the
documentation of shiny::runApp() for more information).</p>
<hr>
</div>
<div class="section level2">
<h2 id="tab-1-data-module">4.2 - Tab 1: data module<a class="anchor" aria-label="anchor" href="#tab-1-data-module"></a>
</h2>
<p>Once the app opens, you will be presented with the “Data” tab. First,
you need to select a video by clicking the <code>Select video</code>
button. You can also select an optional mask by clicking the
<code>Select mask (optional)</code> button. This will load the video in
the app and you can navigate it using the slider under the display
panel. The slider has three handles:</p>
<ul>
<li>the green handle allows you to navigate through the video to display
a frame of your choice;</li>
<li>the two grey handles allow you to restrict the processing of the
video to a range of frames in the video. This can be convenient when
only a portion of the video is usable, for instance.</li>
</ul>
<p>Finally, you will need to select a trained YOLO dataset by clicking
the <code>Select trained dataset</code> button and navigate to a folder
containing a trained YOLO dataset (it should a folder named
<code>YOLO</code>). Select this folder. If the folder contains multiple
trained models, you can select the one of your choice using the dropdown
menu at the bottom of the sidebar.</p>
<p><img src="../reference/figures/track/1_data.jpg"></p>
<p>Once the video and trained dataset are loaded in the app, the second
tab of the app will become available and you can click on it to navigate
there.</p>
<hr>
</div>
<div class="section level2">
<h2 id="tab-2-tracking-module">4.3 - Tab 2: tracking module<a class="anchor" aria-label="anchor" href="#tab-2-tracking-module"></a>
</h2>
<p>In the second tab of the tracking app, you can set the parameters for
the object detection and tracking. The detection parameters are used by
YOLO to decide which parts of the image contains an object of interest.
These parameters are:</p>
<ul>
<li>
<strong>Maximum number of objects to detect:</strong> Maximum number
of detections allowed per frame. Limits the total number of objects the
model can detect in a single inference, preventing excessive outputs in
dense scenes.</li>
<li>
<strong>Minimum confidence threshold:</strong> the minimum
confidence threshold for detections. Objects detected with confidence
below this threshold will be disregarded. Adjusting this value can help
reduce false positives.</li>
<li>
<strong>Intersection over union threshold:</strong> threshold for
non-maximum suppression. Lower values result in fewer detections by
eliminating overlapping boxes, which can be useful for reducing
duplicates.</li>
</ul>
<p>The effect of these parameters on the detection quality can be seen
directly in display panel.</p>
<p><img src="../reference/figures/track/2_tracking.jpg"></p>
<p>The tracking parameters are used by YOLO to decide which object in a
given frame corresponds to which object in the following frame. These
parameters are:</p>
<ul>
<li>
<strong>Association thresholds:</strong> The highest value is the
threshold used for initial association of a detection with a track. If
the detection’s score is above this threshold, it could be associated in
the first round. The lowest value is the threshold used for secondary
association. If a detection wasn’t associated in the first round and its
score is higher than this, it might still be associated in a second
round.</li>
<li>
<strong>New track threshold:</strong> This is the threshold used for
starting a new track. If a detection doesn’t match any existing tracks
and its score is above this threshold, a new track will be
initialized.</li>
<li>
<strong>Old track buffer:</strong> This is the number of frames
allowed to pass without receiving updates from a track before it will be
removed. Higher values allow tracks to remain active longer without
updates, which might help with intermittent detections but could
increase the risk of tracking errors.</li>
<li>
<strong>Track matching threshold:</strong> This threshold is used
for matching tracks between consecutive frames. Only tracks with a score
above this threshold are considered for matching.</li>
</ul>
<p>You cannot directly observe the effect of this parameters in the
display panel. However, you can run the tracking on a small portion of
the video and use the <code>Show preview</code> mode to evaluate the
quality of the resulting tracks.</p>
<p>Once you are satisfied with the selected parameters, you can start
the tracking by clicking the <code>Start tracking</code> button. It will
open a file browser where you can select where to save the results of
the tracking. If you would like to see a preview of the tracks while the
tracking is running, tick the <code>Show preview</code> tick box.</p>
<p><img src="../reference/figures/track/3_tracking.jpg"></p>
<p>Once the tracking has completed, you can visualize the results using
the <a href="https://swarm-lab.github.io/trackRai/articles/z5_visualize.html">visualization
app</a>.</p>
<hr>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Simon Garnier, National Science Foundation, Award ID 2222418.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
