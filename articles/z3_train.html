<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>3. Training a YOLO model • trackRai</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><script src="z3_train_files/libs/quarto-html/popper.min.js"></script><script src="z3_train_files/libs/quarto-html/tippy.umd.min.js"></script><link href="z3_train_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="z3_train_files/libs/quarto-html/light-border.css" rel="stylesheet">
<!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="3. Training a YOLO model">
<meta property="og:image" content="https://swarm-lab.github.io/trackRai/logo.svg">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">trackRai</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/z1_install.html">1. Installing trackRai</a></li>
    <li><a class="dropdown-item" href="../articles/z2_1_prepare_video.html">2.1. Optimizing a video for YOLO</a></li>
    <li><a class="dropdown-item" href="../articles/z2_prepare_auto.html">2.2. Preparing a training dataset (automatic annotation)</a></li>
    <li><a class="dropdown-item" href="../articles/z2_prepare_manual.html">2.3. Preparing a training dataset (manual annotation)</a></li>
    <li><a class="dropdown-item" href="../articles/z3_train.html">3. Training a YOLO model</a></li>
    <li><a class="dropdown-item" href="../articles/z4_track.html">4. Tracking objects</a></li>
    <li><a class="dropdown-item" href="../articles/z5_fix.html">5. Fixing tracks</a></li>
    <li><a class="dropdown-item" href="../articles/z6_visualize.html">6. Visualizing tracks</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/swarm-lab/trackRai/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-quarto">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>3. Training a YOLO model</h1>

      <p class="author">Simon Garnier</p>


      <small class="dont-index">Source: <a href="https://github.com/swarm-lab/trackRai/blob/master/vignettes/z3_train.qmd" class="external-link"><code>vignettes/z3_train.qmd</code></a></small>
      <div class="d-none name"><code></code></div>
    </div>






    <section class="level2"><h2 id="introduction">0. Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Once you are ready to train a YOLO model, you can launch trackRai by typing the following command in the R console:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/swarm-lab/trackRai" class="external-link">trackRai</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/trackRai.html">trackRai</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="images/z0.jpg" class="quarto-figure quarto-figure-center" style="border-radius: 5px; border-style: groove;;width:40.0%"></p>
</figure>
</div>
<p>This will open the app launcher either in the viewer pane of RStudio and Positron, or in a separate window, depending on your local configuration. In RStudio at least, you can control where the app opens by setting the <code>launch.browser</code> option. For instance:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/trackRai.html">trackRai</a></span><span class="op">(</span>launch.browser <span class="op">=</span> <span class="fu">shiny</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/shiny/man/viewer.html" class="external-link">paneViewer</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<p>will launch the app in the RStudio viewer pane.</p>
<p>Once the launcher is running, click on the “Train” button to launch the YOLO training app. The launcher will close and the app will start shortly after. This app will help you train a YOLO11 model using the dataset created in the previous tutorial. The process is straightforward, however, it might take some time depending on the configuration of your system. A machine with an NVIDIA graphics card and the CUDA framework installed is highly recommended.</p>
<hr></section><section class="level2"><h2 id="training-module">1. Training module<a class="anchor" aria-label="anchor" href="#training-module"></a>
</h2>
<p>Once the app opens, you will be presented with the “Training” tab. Click on the “Select training dataset” button and navigate to a folder containing a YOLO dataset as prepared in one of the previous tutorials (it should a folder named “YOLO”). Select this folder.</p>
<p>Then, select a model size. Smaller models take less time and memory to train, larger models may yield better results for complex arrangements of objects. We find that the smaller (“nano”) model size does a really good job in most situations.</p>
<p>Finally, you can “Set the number of training epochs” you would like to run and the “patience” of the training process. This last parameter allows the training to stop automatically if the training performance does not improve after a set number of epochs. This helps prevent overfitting by stopping training when performance plateaus; it also saves computing time. If you do not want training to stop early, set the patience to the maximum number of epochs.</p>
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="images/z3_1.jpg" class="quarto-figure quarto-figure-center" style="border-radius: 5px; border-style: groove;"></p>
</figure>
</div>
<p>After setting all the training parameters, click the “Start training” button and wait until it completes. Performance metrics will be displayed in the graph on the left of the window, and in the log panel below the graph.</p>
<p>Once the training has completed successfully, the second tab of the app will become available and you can click on it to navigate there.</p>
<hr></section><section class="level2"><h2 id="checking-module">2. Checking module<a class="anchor" aria-label="anchor" href="#checking-module"></a>
</h2>
<p>In the second tab of the training app, you can check the quality of the training and the effect of the inference parameters on the detection of the objects of interest in a video.</p>
<p>First, you need to select a video by clicking the “Select video” button. You can also select an optional mask by clicking the “Select mask (optional)” button. This will load the video in the app and you navigate through it by sliding the green tab along the timeline displayed below the video. You can also use the arrow keys on your keyboard to navigate through the video: the left and right arrows allow you to navigate frame by frame; the up and down arrows allow you to navigate one second at a time. Detected objects will be automatically enclosed in a colored rectangle and their class will be overlaid on top of them (you can show/hide the boxes and class tags by using the corresponding tick boxes at the bottom of the control panel).</p>
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="images/z3_2.jpg" class="quarto-figure quarto-figure-center" style="border-radius: 5px; border-style: groove;"></p>
</figure>
</div>
<p>You can check the effect of the following parameters on the quality of the object detection:</p>
<ul>
<li>
<strong>Minimum confidence threshold:</strong> the minimum confidence threshold for detection. Objects detected with confidence below this threshold will be disregarded. Adjusting this value can help reduce false positives.</li>
<li>
<strong>Intersection over union threshold:</strong> threshold for non-maximum suppression. Lower values result in fewer detection by eliminating overlapping boxes, which can be useful for reducing duplicates.</li>
<li>
<strong>Maximum number of objects to detect:</strong> Maximum number of detection allowed per frame. Limits the total number of objects the model can detect in a single inference, preventing excessive outputs in dense scenes.</li>
</ul>
<p>If you are not satisfied with the detection results, you can return to the first tab and increase the number of training epochs and/or the patience of the training, or select a larger model size, before running another round of training.</p>
<p>If you are satisfied with the results, you are done and you can close the app. The next step will be using the trained model to track objects in a video.</p>
<hr>
<p>The video used throughout this tutorial was provided by <em>Sridhar, V. H., Roche, D. G., and Gingins, S. (2019). Tracktor: Image-based automated tracking of animal movement and behaviour. Methods Ecol. Evol. 10, 691. doi:10.1111/2041-210X.13166</em> and used here with permission of the authors.</p>
</section><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config);
    }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script></main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Simon Garnier, National Science Foundation, Award ID 2222418.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
